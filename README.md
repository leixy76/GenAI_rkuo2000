# Generative AI

**[AIGC 教材](https://rkuo2000.github.io/AI-course/lecture/2024/08/12/AIGC.html)** <br>
**[GenAI-projects 教材](https://rkuo2000.github.io/GenAI-projects/)** <br>

**範例程式：** `git clone https://github.com/rkuo2000/GenAI`<br>

---
## 1. Text-to-Image 
* `sdxl-base.py` - run SDXL-base model to input text and generate an image
* `sdxl-lightning-lora.py` - run SDXL-Lightning with LoRA model to use text to generate an image
* `sdxl-lightning-unet.py` - run SDXL-Lightning with UNet model to use text to generate an image

### Image Creators

#### [Bing-Create tutorial](https://rkuo2000.github.io/GenAI-projects/Bing-Create/)

#### [Midjourney](https://www.midjourney.com/home)

#### [Leonardo.ai](https://app.leonardo.ai/)

#### [civitai](https://civitai.com/)

#### [SeaArt.ai](https://www.seaart.ai/)

#### [TensorArt](https://tensor.art/)

#### [OpenArt.ai](https://openart.ai/)

#### [fluxpro.ai](https://www.fluxpro.ai/)
[![](https://markdown-videos-api.jorgenkh.no/youtube/gZTQiyQCgUw)](https://youtu.be/gZTQiyQCgUw)

---
### ComfyUI / WebUI

#### Flux.1 本地部署！媲美Midjourney的頂級AI繪圖模型
[![](https://markdown-videos-api.jorgenkh.no/youtube/87TwZ05SSGc)](https://youtu.be/87TwZ05SSGc)

#### AI繪畫(Stable Diffusion),在WebUI Forge和ComfyUI使用
[![](https://markdown-videos-api.jorgenkh.no/youtube/uTqLiNo2GzI)](https://youtu.be/uTqLiNo2GzI)

---
### Krita

#### FLUX.1[dev]模型在Krita完美整合
[![](https://markdown-videos-api.jorgenkh.no/youtube/Y99_C0C28UE)](https://youtu.be/Y99_C0C28UE)

---
## 2. Text-to-3D
**gTranslate + SDXL-Lightning + TripoSR + Blender**<br>

---
## Image-to-3D

### [Zero123+++](https://github.com/SUDO-AI-3D/zero123plus)
* [https://www.kaggle.com/code/rkuo2000/zero123plus](https://www.kaggle.com/code/rkuo2000/zero123plus)<br>
* [https://www.kaggle.com/code/rkuo2000/zero123-controlnet](https://www.kaggle.com/code/rkuo2000/zero123-controlnet)<br>

---
### [TripoSR](https://github.com/VAST-AI-Research/TripoSR)
![](https://favtutor.com/articles/wp-content/uploads/2024/03/TripoSR-Image-to-3D-Objects-Examples.gif)
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/triposr](https://www.kaggle.com/code/rkuo2000/triposr)<br>

---
### Depth Pro
**Code:** [https://github.com/apple/ml-depth-pro](https://github.com/apple/ml-depth-pro)
![](https://github.com/apple/ml-depth-pro/raw/main/data/depth-pro-teaser.jpg)
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/depth-pro](https://www.kaggle.com/code/rkuo2000/depth-pro)<br>

---
## 3. Text-to-Video/Motion

### [Tune-A-Video](https://github.com/showlab/Tune-A-Video)
![](https://camo.githubusercontent.com/3a1fe691700facadce50b7dd66641abdc40ce5a97b53e85091d5af0f273481a1/68747470733a2f2f74756e6561766964656f2e6769746875622e696f2f6173736574732f7465617365722e676966)

---
### [Open-VCLIP](https://github.com/wengzejia1/Open-VCLIP/)
![](https://github.com/wengzejia1/Open-VCLIP/raw/main/figures/firstpage.png)

---
### [Dynamic Scene Transformer (DyST)](https://dyst-paper.github.io/)
![](https://dyst-paper.github.io/data/model_fig.png)

---
### [Text-to-Motion-Retrieval](https://github.com/mesnico/text-to-motion-retrieval)
<p><img src="https://github.com/mesnico/text-to-motion-retrieval/raw/main/teaser/example_74.gif"></p>
<p><img src="https://github.com/mesnico/text-to-motion-retrieval/raw/main/teaser/example_243.gif"></p>

---
### [Stable Video Diffusion](https://stability.ai/news/stable-video-diffusion-open-ai-video-model)
![](https://github.com/Stability-AI/generative-models/raw/main/assets/sv4d.gif)

**[SV4D](https://github.com/Stability-AI/generative-models)** <br>
SV4D was trained to generate 40 frames (5 video frames x 8 camera views) at 576x576 resolution

---
### [Runway Gen3](https://runwayml.com/)
[![](https://markdown-videos-api.jorgenkh.no/youtube/SAxZB7wUWYo)](https://youtu.be/SAxZB7wUWYo)

[![](https://markdown-videos-api.jorgenkh.no/youtube/nByslCkykj8)](https://youtu.be/nByslCkykj8)

[Gen-3 Alpha Prompting Guide](https://help.runwayml.com/hc/en-us/articles/30586818553107-Gen-3-Alpha-Prompting-Guide)<br>

---
### [Imagine.Art](https://www.imagine.art/dashboard)<br>

---
### SORA
[![](https://markdown-videos-api.jorgenkh.no/youtube/IBVAf7XJCFg)](https://youtu.be/IBVAf7XJCFg)

---
### [Meta MovieGen](https://ai.meta.com/research/movie-gen/)
[![](https://markdown-videos-api.jorgenkh.no/youtube/FHSSx4dUs7E)](https://youtu.be/FHSSx4dUs7E)

---
## 4. Text-to-Avatar

### [HeyGen](https://www.heygen.com/)

### [Hedra](https://www.hedra.com/)
**[Tutorial](https://rkuo2000.github.io/GenAI-projects/Hedra/)** <br>
[![](https://markdown-videos-api.jorgenkh.no/youtube/wBO0VsiWC2s)](https://youtu.be/wBO0VsiWC2s)

### [LivePortrait](https://github.com/KwaiVGI/LivePortrait)
**[Tutorial](https://rkuo2000.github.io/GenAI-projects/LivePortrait/)** <br>
![](https://github.com/KwaiVGI/LivePortrait/raw/main/assets/docs/showcase2.gif)

### [MuskTalk](https://github.com/TMElyralab/MuseTalk)
 <video src=https://github.com/TMElyralab/MuseTalk/assets/163980830/b2a879c2-e23a-4d39-911d-51f0343218e4 controls preload></video>

---
## 5. Text-to-Song 

### [Suno 教學](https://rkuo2000.github.io/GenAI-projects/Suno/)

### [Tuneform](https://tuneform.com/)
[![](https://markdown-videos-api.jorgenkh.no/youtube/_VTfbR5VT4s)](https://youtu.be/_VTfbR5VT4s)

### [Specterr](https://specterr.com/)
[![](https://markdown-videos-api.jorgenkh.no/youtube/MJPuGL-aGzA)](https://youtu.be/MJPuGL-aGzA)

### [Vizzy](https://vizzy.io)
[![](https://markdown-videos-api.jorgenkh.no/youtube/gUko_GnT40g)](https://youtu.be/gUko_GnT40g)

[![](https://markdown-videos-api.jorgenkh.no/youtube/sFaMRk7TGpk)](https://youtu.be/sFaMRk7TGpk)

[![](https://markdown-videos-api.jorgenkh.no/youtube/BvsP4ivkVyM)](https://youtu.be/BvsP4ivkVyM)

---
## [Generative Speech](https://rkuo2000.github.io/AI-course/lecture/2024/08/09/Generative-Speech.html)
* `python gTTS.py "How are you" en` : generate gTTS.mp3
* `python gT2T.py "How are you" fr` : deep-translator 
* `python gSpeak.py "How are you" fr` : deep-translator, gTTS & Mpg123

---
### SunoAI + RVC WebUI + ChatGPT
[![](https://markdown-videos-api.jorgenkh.no/youtube/9nHbw0eUJeE)](https://youtu.be/9nHbw0eUJeE)

#### [RVC-WebUI開源專案教學](https://gogoplus.net/%E7%BF%BB%E5%94%B1%E6%9C%80%E5%A5%BD%E7%94%A8%E7%9A%84%E9%96%8B%E6%BA%90%E7%A8%8B%E5%BC%8F-rvc-webui-%E5%85%8B%E9%9A%86%E4%BD%A0%E7%9A%84%E8%81%B2%E9%9F%B3/)

**[RVC WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)** <br>

---
## 6. Text-to-Speech

* **Parler TTS**: `python parler.py`
* **Bark TTA**: `python bark_en.py`, `python bark_cn.py`
* **Coqui TTS**: `python coqui_en.py`, `python coqui_zh.py`
* **text-to-speech**: `python text_to_speech.py`
* **gTTS**: `python gTTS.py "你好?" zh`
* **gTranslate**: `python gTranslate.py`
  
---
## 7. Audio-to-Text (ASR)

### webkitSpeechRecognition
**Blog:** [語音辨識API](https://programmermagazine.github.io/201310/htm/article2.html)<br>

[asr.html](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/asr.html)<br>

[Google Speech Demo](https://www.google.com/intl/en/chrome/demos/speech.html)<br>

---
### Whisper
* [whisper.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/whisper.py)
* [whisper-large-v3.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/whisper-large-v3.py)
* [faster-whisper.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/faster-whisper.py)
* [canary-1b.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/canary-1b.py)
<br>

* [qwen_audio.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/qwen_audio.py)
* [gemini_audio.py](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/gemini_audio.py)

---
### local ASR+LLM Server running on GPU
1. **run server on local PC (with GPU):** `python whisper_llm_server.py`<br>
2. **Generate audio file**: `python ../gTTS.py "Hello, how are you?" en`<br>
3. **Post Audio to Server**: `python post_audio.py`<br>

---
## 8. Text-to-Text (LLMs)

**[Large Language Models 教材](https://rkuo2000.github.io/AI-course/lecture/2024/08/15/LLM.html)** <br>
**[Prompt Engineering 教材](https://rkuo2000.github.io/AI-course/lecture/2024/08/15/Prompt-Engineering.html)** <br>

`git clone https://github.com/rkuo2000/GenAI`<br>
`cd GenAI/Text-to-Text`<br>

* `python gpt4free.py` (gpt-3.5-turbo)
* `python gpt4all_prompting.py`
* `python LLM_prompting.py`
* [colab_LLM_prompting.ipynb](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/colab_LLM_prompting.ipynb) (on Colab T4) 

#### local LLM Server & Client
* `python llm_server.py` (on GPU)
* `python post_text.py`  (on PC)

---
### Colab running LLM Server
* [colab_pyNgrok_LLM_server](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/colab_pyNgrok_LLM_Server.ipynb) (on Colab T4)<br>
![](https://github.com/rkuo2000/GenAI/blob/main/assets/pyngrok_LLM_Server_fastapi.png?raw=true)
* [post-text client](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/post_text.py) (on PC)<br>
![](https://github.com/rkuo2000/GenAI/blob/main/assets/pyngrok_post_text.png?raw=true)

---
### Colab running ASR+LLM Server
1. **Open [colab](https://colab.research.google.com) to run [pyngrok_Whisper_LLM_Server.ipynb](https://github.com/rkuo2000/GenAI/blob/main/Audio-to-Text/pyngrok_Whisper_LLM_Server.ipynb)** on Colab T4
2. **Generate audio file**: `python ../gTTS.py "Hello, how are you?" en`<br>
3. **Post Audio to Server**: `python post_audio.py`<br>
![](https://github.com/rkuo2000/GenAI/blob/main/assets/post_audio.png?raw=true)

---
### [Ollama](https://ollama.com/)

#### [ollama library](https://ollama.com/library)
`ollama list`<br>
`ollama run llama3.2`<br>

#### ollama chat/generate
* `python ollama_chat.py`
* `python ollama_stream.py` (print text in streaming mode)
* `python ollama_curl.py`

#### ollama speak
* `python ollama_speak.py` (ollama generated text, gTTS to speech, then mpg123 to speak)
* `python ollama_speak_t2t.py` (ollama generated text, gTTS to speech, deep-translator to zh-TW, mpg123 to speak)

---
### [LM Studio](https://lmstudio.ai/)
![](https://github.com/rkuo2000/GenAI/blob/main/assets/LM_Studio_0.3.3.png?raw=true)

---
### [Gemini API](https://ai.google.dev/api/generate-content?hl=zh-tw)

* [gemini.html](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/gemini.html)
  
* `Gemini_Talk.aia` : MIT App Inventor 2 example for using Google Gemini

---
## 9. LLM Fine-Tuning
**[LLM Fine-Tuning 教材](https://rkuo2000.github.io/AI-course/lecture/2024/08/17/LLM-FineTuning.html)** <br>

### PEFT
[fine-tune-gemma-7b-it-for-sentiment-analysis](https://www.kaggle.com/code/rkuo2000/fine-tune-gemma-7b-it-for-sentiment-analysis)<br>
[fine-tune-llama-3-for-sentiment-analysis](https://www.kaggle.com/code/rkuo2000/fine-tune-llama-3-for-sentiment-analysis)<br>

### LoRA
[fine-tune-gemma-models-in-keras-using-lora](https://www.kaggle.com/code/rkuo2000/fine-tune-gemma-models-in-keras-using-lora)<br>

---
## 10. Image-to-Text (VLM)

---
### examples
* `python llava-1.5-7b-hf.py`<br>
* `python llava-1.6-7b-hf.py`<br>
* `python phi-3.5-vision.py`<br>
* `python llama-3.2-vision.py`<br>

---
### VLM servers
For running server, (use one of the following)<br>
1. `python llava_server.py`
2. `python llava_next_server.py`
3. `python phi3-vision_server.py`

For running client, (post image & text to VLM server)<br>
`python post_imgtxt.py images/barefeet1.jpg`<br>

---
### ASR + VLM servers
1. `python whisper_llava_server.py`
2. `python ../gTTS.py "這是什麼有名的台南美食?" zh` (TTS)<br>
3. `python post_imgau.py` (client)<br>

---
### [Gemini API](https://ai.google.dev/api/generate-content?hl=zh-tw)
* `python gemini_image.py`<br>
* `python gemini_jpg2csv.py`<br>

---
## 11. RAG 
**[RAG 教材](https://rkuo2000.github.io/AI-course/lecture/2024/08/18/RAG.html)** <br>
![](https://blogs.mathworks.com/deep-learning/files/2024/01/rag.png)

### Sampe Codes
* [https://www.kaggle.com/code/rkuo2000/langchain-rag-chromadb](https://www.kaggle.com/code/rkuo2000/langchain-rag-chromadb)
* [https://www.kaggle.com/code/rkuo2000/llm-llamaindex](https://www.kaggle.com/code/rkuo2000/llm-llamaindex) = LlamaIndex-RAG-pdf
* Langchain-RAG-text.ipynb
* Langchain-ReAct.ipynb
* LlamaIndex-RAG-pdf.ipynb
* LlamaIndex-RAG-pdf-community.ipynb
* LlamaIndex-RAG-pdf-community.py

---
### [RAG Builder](https://github.com/KruxAI/ragbuilder)

---
## 12. Agent
**[Agent 教材](https://rkuo2000.github.io/AI-course/lecture/2024/09/28/AI-Agents.html)** <br>

### [openai/swarm](https://github.com/openai/swarm)
`cd ~/GenAI`<br>
`git clone https://github.com/openai/swarm`<br>
`pip install git+https://github.com/openai/swarm.git`<br>

![](https://github.com/openai/swarm/raw/main/assets/swarm_diagram.png)
